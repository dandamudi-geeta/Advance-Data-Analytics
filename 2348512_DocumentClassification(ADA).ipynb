{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkebh6jl7I0A",
        "outputId": "bd58a842-4425-4cea-cb0f-fbd78e711237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Load the train set\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "\n",
        "# Load the test set\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\n"
      ],
      "metadata": {
        "id": "ZbeCbx3D7I2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print information about the dataset\n",
        "print(\"Training set size:\", len(newsgroups_train.data))\n",
        "print(\"Test set size:\", len(newsgroups_test.data))\n",
        "print(\"Number of categories:\", len(newsgroups_train.target_names))\n",
        "print(\"Categories:\", newsgroups_train.target_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLP8cboL7I4w",
        "outputId": "5d2bc8ab-0671-475a-9aef-625ac3135d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 11314\n",
            "Test set size: 7532\n",
            "Number of categories: 20\n",
            "Categories: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(newsgroups_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "rO5A-rLv7I69",
        "outputId": "1574e03d-66b3-4eee-ee2a-2e084c21373a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sklearn.utils._bunch.Bunch</b><br/>def __init__(**kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/sklearn/utils/_bunch.py</a>Container object exposing keys as attributes.\n",
              "\n",
              "Bunch objects are sometimes used as an output for functions and methods.\n",
              "They extend dictionaries by enabling values to be accessed by key,\n",
              "`bunch[&quot;value_key&quot;]`, or by an attribute, `bunch.value_key`.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from sklearn.utils import Bunch\n",
              "&gt;&gt;&gt; b = Bunch(a=1, b=2)\n",
              "&gt;&gt;&gt; b[&#x27;b&#x27;]\n",
              "2\n",
              "&gt;&gt;&gt; b.b\n",
              "2\n",
              "&gt;&gt;&gt; b.a = 3\n",
              "&gt;&gt;&gt; b[&#x27;a&#x27;]\n",
              "3\n",
              "&gt;&gt;&gt; b.c = 6\n",
              "&gt;&gt;&gt; b[&#x27;c&#x27;]\n",
              "6</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "stops_Wrods = set(stopwords.words('english'))\n",
        "lemmitizer = WordNetLemmatizer()\n",
        "\n",
        "def text_preprocessing(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    text = ' '.join([lemmitizer.lemmatize(word) for word in word_tokenize(text) if word not in stops_Wrods])\n",
        "    words = word_tokenize(text)\n",
        "    words = [lemmitizer.lemmatize(word) for word in words if word.isalpha()]\n",
        "    return ' '.join(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5unrATOqFm3Q",
        "outputId": "209b0cb1-7402-4afc-ae57-6593fed7d364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the traing and test data\n",
        "newsgroups_train_preprocessed = [text_preprocessing(text) for text in newsgroups_train.data]\n",
        "newsgroups_test_preprocessed = [text_preprocessing(text) for text in newsgroups_test.data]"
      ],
      "metadata": {
        "id": "Dcg8RmAKFm5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a TF -IDF vectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(newsgroups_train_preprocessed)\n",
        "X_test = vectorizer.transform(newsgroups_test_preprocessed)\n",
        "\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target"
      ],
      "metadata": {
        "id": "-QaneFlPCEyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n"
      ],
      "metadata": {
        "id": "pAZ_kHSzIs-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the classifiers\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "logistic_regression_classifier = LogisticRegression()\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "\n",
        "classifiers = [naive_bayes_classifier, svm_classifier, logistic_regression_classifier, random_forest_classifier]\n",
        "classifier_names = ['Naive Bayes', 'SVM', 'Logistic Regression', 'Random Forest']\n",
        "\n",
        "# Iterate over each classifier and evaluate its accuracy\n",
        "for clf, clf_name in zip(classifiers, classifier_names):\n",
        "    clf.fit(X_train, y_train)  # Train the classifier\n",
        "    y_pred = clf.predict(X_test)  # Predict on the test data\n",
        "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
        "    print(f\"{clf_name} Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbNvsbQhItDW",
        "outputId": "03e1b70e-e5d1-4128-887a-8b1178a6b9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.8087\n",
            "SVM Accuracy: 0.8310\n",
            "Logistic Regression Accuracy: 0.8245\n",
            "Random Forest Accuracy: 0.7605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "num_cluster = 20\n",
        "kmeans = KMeans(n_clusters=num_cluster, random_state=4)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "kmeans_labels = kmeans.labels_\n",
        "silhouette_avg = silhouette_score(X_train, kmeans_labels)\n",
        "print(f\"Silhouette score for KMeans clustering: {silhouette_avg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSeNJTQqOPwB",
        "outputId": "dcb8e72e-c91f-42eb-e2c3-c4a884b8097a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette score for KMeans clustering: 0.0079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# **Feature Extraction using CountVectorizer**\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=10000)\n",
        "\n",
        "# Fit and transform the training and test data\n",
        "X_train_count = count_vectorizer.fit_transform(newsgroups_train_preprocessed)\n",
        "X_test_count = count_vectorizer.transform(newsgroups_test_preprocessed)\n",
        "\n",
        "# **Model Evaluation using Support Vector Machine (SVM)**\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train_count, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_count_svm = svm_classifier.predict(X_test_count)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_count_svm = accuracy_score(y_test, y_pred_count_svm)\n",
        "\n",
        "print(f\"SVM Accuracy with CountVectorizer: {accuracy_count_svm:.4f}\")\n",
        "\n",
        "\n",
        "# **Feature Extraction using CountVectorizer**\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=10000)\n",
        "\n",
        "# Fit and transform the training and test data\n",
        "X_train_count = count_vectorizer.fit_transform(newsgroups_train_preprocessed)\n",
        "X_test_count = count_vectorizer.transform(newsgroups_test_preprocessed)\n",
        "\n",
        "# **Model Evaluation using Support Vector Machine (SVM)**\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train_count, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_count_svm = svm_classifier.predict(X_test_count)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_count_svm = accuracy_score(y_test, y_pred_count_svm)\n",
        "\n",
        "print(f\"SVM Accuracy with CountVectorizer: {accuracy_count_svm:.4f}\")\n",
        "# prompt: NameError: name 'XGBClassifier' is not defined\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = XGBClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "xgb_classifier.fit(X_train_count, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_count_xgb = xgb_classifier.predict(X_test_count)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_count_xgb = accuracy_score(y_test, y_pred_count_xgb)\n",
        "\n",
        "print(f\"XGBoost Accuracy with CountVectorizer: {accuracy_count_xgb:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ltrqRupVFQr",
        "outputId": "3d89fb8b-8900-4681-dfd0-96d2226dd609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy with CountVectorizer: 0.7321\n",
            "SVM Accuracy with CountVectorizer: 0.7321\n",
            "XGBoost Accuracy with CountVectorizer: 0.7623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Calculate and print the silhouette score for the SVM clustering\n",
        "kmeans_labels_svm = kmeans.fit_predict(X_train_count)\n",
        "silhouette_avg_svm = silhouette_score(X_train_count, kmeans_labels_svm)\n",
        "print(f\"Silhouette score for SVM clustering: {silhouette_avg_svm:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glhMOtmMVFTC",
        "outputId": "81014012-e245-4cef-9a1e-ba8e09e64ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette score for SVM clustering: 0.5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2_OwoHNwVFWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}